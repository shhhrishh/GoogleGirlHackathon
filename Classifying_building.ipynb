{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBw5RNvl2ohj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha ../input/satellite-images-of-hurricane-damage"
      ],
      "metadata": {
        "id": "D7rXVsiq2qYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = '../input/satellite-images-of-hurricane-damage/'\n",
        "\n",
        "def print_file_sizes(input_path, subset):\n",
        "    print('{}:'.format(subset))\n",
        "    print('')\n",
        "    path = input_path + subset + '/'\n",
        "    for f in os.listdir(path):\n",
        "        if not os.path.isdir(path + f):\n",
        "            print(f.ljust(30) + str(round(os.path.getsize(path + f) / 1000000, 2)) + 'MB')\n",
        "        else:\n",
        "            sizes = [os.path.getsize(path+f+'/'+x)/1000000 for x in os.listdir(path + f)]\n",
        "            print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + ' ({} files)'.format(len(sizes)))\n",
        "    print('')\n",
        "\n",
        "print_file_sizes(input_path, 'train_another')\n",
        "print_file_sizes(input_path, 'validation_another')\n",
        "print_file_sizes(input_path, 'test_another')\n",
        "print_file_sizes(input_path, 'test')"
      ],
      "metadata": {
        "id": "5fFPXy5N2qdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n",
        "\n",
        "s = 3\n",
        "alpha = 0.25\n",
        "\n",
        "# get the train-validation-test splits\n",
        "image_df_train = image_df[image_df['data_split']=='train_another'].copy()\n",
        "image_df_val = image_df[image_df['data_split']=='validation_another'].copy()\n",
        "image_df_test = image_df[image_df['data_split']=='test_another'].copy()\n",
        "\n",
        "# sort to ensure reproducible behaviour\n",
        "image_df_train.sort_values('lat', inplace=True)\n",
        "image_df_val.sort_values('lat', inplace=True)\n",
        "image_df_test.sort_values('lat', inplace=True)\n",
        "image_df_train.reset_index(drop=True,inplace=True)\n",
        "image_df_val.reset_index(drop=True,inplace=True)\n",
        "image_df_test.reset_index(drop=True,inplace=True)\n",
        "\n",
        "ax[0].scatter(image_df_train['lon'], image_df_train['lat'], color='C0', s=s, alpha=alpha, label='train')\n",
        "ax[0].scatter(image_df_val['lon'], image_df_val['lat'], color='C1', s=s, alpha=alpha, label='validation')\n",
        "\n",
        "ax[0].set_title('split', fontsize=14, fontweight='bold')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel('longitude')\n",
        "ax[0].set_ylabel('latitude')\n",
        "\n",
        "image_df_dmg = image_df[image_df['damage']=='damage'].copy()\n",
        "image_df_nodmg = image_df[image_df['damage']=='no_damage'].copy()\n",
        "\n",
        "image_df_dmg.reset_index(drop=True,inplace=True)\n",
        "image_df_nodmg.reset_index(drop=True,inplace=True)\n",
        "\n",
        "ax[1].scatter(image_df_dmg['lon'], image_df_dmg['lat'], color='C0', s=s, alpha=alpha, label='damage')\n",
        "ax[1].scatter(image_df_nodmg['lon'], image_df_nodmg['lat'], color='C1', s=s, alpha=alpha, label='no damage')\n",
        "\n",
        "ax[1].set_title('label', fontsize=14, fontweight='bold')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel('longitude')\n",
        "ax[1].set_ylabel('latitude')\n",
        "\n",
        "plt.show(fig)"
      ],
      "metadata": {
        "id": "2iRYCUHJ2qgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,6), sharex=True, sharey=True)\n",
        "\n",
        "s = 20\n",
        "alpha = 0.25\n",
        "\n",
        "ax[0].scatter(image_df_dmg['lon'], image_df_dmg['lat'], color='C0', s=s, alpha=alpha, label='damage')\n",
        "ax[0].set_title('damage', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax[1].scatter(image_df_dmg['lon'], image_df_dmg['lat'], color='k', s=s, alpha=alpha, label='damage')\n",
        "ax[1].scatter(image_df_nodmg['lon'], image_df_nodmg['lat'], color='k', s=s, alpha=alpha, label='no damage')\n",
        "ax[1].set_title('all images', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax[2].scatter(image_df_nodmg['lon'], image_df_nodmg['lat'], color='C1', s=s, alpha=alpha, label='no damage')\n",
        "ax[2].set_title('no damage', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax[0].set_ylabel('latitude')\n",
        "ax[0].set_xlabel('longitude')\n",
        "ax[1].set_xlabel('longitude')\n",
        "ax[2].set_xlabel('longitude')\n",
        "\n",
        "ax[0].set_xlim(-95.3,-95)\n",
        "ax[0].set_ylim(29.7,30.2)\n",
        "\n",
        "plt.show(fig)"
      ],
      "metadata": {
        "id": "YCPGR5QI2qiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# read it in unchanged, to make sure we aren't losing any information\n",
        "img = cv2.imread(image_df['path'][0], cv2.IMREAD_UNCHANGED)\n",
        "np.shape(img)"
      ],
      "metadata": {
        "id": "wiX2adDd2qlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(img[0,0,0])"
      ],
      "metadata": {
        "id": "PtLuzy5X2qnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(img[:,:,:])"
      ],
      "metadata": {
        "id": "5fNtSaiu2qph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(img[:,:,:])"
      ],
      "metadata": {
        "id": "Qu1LhuLf2qsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=4, ncols=10, sharex=True, sharey=True, figsize=(20,10))\n",
        "\n",
        "ax = ax.flatten()\n",
        "\n",
        "for i in range(20):\n",
        "    img = cv2.imread(image_df_dmg['path'][i], cv2.IMREAD_UNCHANGED)\n",
        "    ax[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    ax[i].set_title('damage')\n",
        "\n",
        "for i in range(20,40):\n",
        "    img = cv2.imread(image_df_nodmg['path'][i], cv2.IMREAD_UNCHANGED)\n",
        "    ax[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    ax[i].set_title('no damage')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xgU9Vzdb2que"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=4, ncols=3, sharex=True, sharey=True, figsize=(15,20))\n",
        "\n",
        "ax = ax.flatten()\n",
        "\n",
        "selected_dmg = np.array([0,1,2,3,4,5])*100\n",
        "selected_nodmg = np.array([0,1,2,3,4,5])*99\n",
        "\n",
        "for i in range(6):\n",
        "    img = cv2.imread(image_df_dmg['path'][selected_dmg[i]], cv2.IMREAD_UNCHANGED)\n",
        "    ax[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    #ax[i].set_title('damage')\n",
        "\n",
        "for i in range(6):\n",
        "    img = cv2.imread(image_df_nodmg['path'][selected_nodmg[i]], cv2.IMREAD_UNCHANGED)\n",
        "    ax[i+6].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    #ax[i+6].set_title('no damage')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y2zGvDpy2qxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_channels = ['blue','green','red']\n",
        "jpg_channel_colors = ['b','g','r']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "\n",
        "for i in range(len(jpg_channels)):\n",
        "    ax.hist(img[:,:,i].flatten(), bins=np.arange(256),\n",
        "            label=jpg_channels[i], color=jpg_channel_colors[i], alpha=0.5)\n",
        "    ax.legend()\n",
        "\n",
        "ax.set_xlim(0,255)\n",
        "\n",
        "plt.show(fig)"
      ],
      "metadata": {
        "id": "MdO9H9-n3ebm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "xw0pe84C3eed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paths\n",
        "train_path = image_df_train['path'].copy().values\n",
        "val_path = image_df_val['path'].copy().values\n",
        "test_path = image_df_test['path'].copy().values\n",
        "\n",
        "# labels\n",
        "train_labels = np.zeros(len(image_df_train), dtype=np.int8)\n",
        "train_labels[image_df_train['damage'].values=='damage'] = 1\n",
        "\n",
        "val_labels = np.zeros(len(image_df_val), dtype=np.int8)\n",
        "val_labels[image_df_val['damage'].values=='damage'] = 1\n",
        "\n",
        "test_labels = np.zeros(len(image_df_test), dtype=np.int8)\n",
        "test_labels[image_df_test['damage'].values=='damage'] = 1"
      ],
      "metadata": {
        "id": "SiP9zeme3ehE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((train_path, train_labels))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_path, val_labels))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_path, test_labels))\n",
        "\n",
        "# note that the `numpy()` function is required to grab the actual values from the Dataset\n",
        "for path, label in train_ds.take(5):\n",
        "    print(\"path  : \", path.numpy().decode('utf-8'))\n",
        "    print(\"label : \", label.numpy())"
      ],
      "metadata": {
        "id": "pSoyZT-93ej7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function wraps `cv2.imread` - we treat it as a 'standalone' function, and therefore can use\n",
        "# eager execution (i.e. the use of `numpy()`) to get a string of the path.\n",
        "# note that no tensorflow functions are used here\n",
        "def cv2_imread(path, label):\n",
        "    # read in the image, getting the string of the path via eager execution\n",
        "    img = cv2.imread(path.numpy().decode('utf-8'), cv2.IMREAD_UNCHANGED)\n",
        "    # change from BGR to RGB\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img, label\n",
        "\n",
        "# this function assumes that the image has been read in, and does some transformations on it\n",
        "# note that only tensorflow functions are used here\n",
        "def tf_cleanup(img, label):\n",
        "    # convert to Tensor\n",
        "    img = tf.convert_to_tensor(img)\n",
        "    # unclear why, but the jpeg is read in as uint16 - convert to uint8\n",
        "    img = tf.dtypes.cast(img, tf.uint8)\n",
        "    # set the shape of the Tensor\n",
        "    img.set_shape((128, 128, 3))\n",
        "    # convert to float32, scaling from uint8 (0-255) to float32 (0-1)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    # resize the image\n",
        "    img = tf.image.resize(img, [128, 128])\n",
        "    # convert the labels into a Tensor and set the shape\n",
        "    label = tf.convert_to_tensor(label)\n",
        "    label.set_shape(())\n",
        "    return img, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# map the cv2 wrapper function using `tf.py_function`\n",
        "train_ds = train_ds.map(lambda path, label: tuple(tf.py_function(cv2_imread, [path, label], [tf.uint16, label.dtype])),\n",
        "                        num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(lambda path, label: tuple(tf.py_function(cv2_imread, [path, label], [tf.uint16, label.dtype])),\n",
        "                    num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.map(lambda path, label: tuple(tf.py_function(cv2_imread, [path, label], [tf.uint16, label.dtype])),\n",
        "                      num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# map the TensorFlow transformation function - no need to wrap\n",
        "train_ds = train_ds.map(tf_cleanup, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(tf_cleanup, num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.map(tf_cleanup, num_parallel_calls=AUTOTUNE)"
      ],
      "metadata": {
        "id": "y5_gk6Z13emi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_augmentation(img, label):\n",
        "    # rotate 0, 90, 180, or 270 degrees with 25% probability for each\n",
        "    img = tf.image.rot90(img, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32, seed=1111))\n",
        "    return img, label\n",
        "\n",
        "def flip_augmentation(img, label):\n",
        "    # flip with 50% probability for left-right and up-down\n",
        "    img = tf.image.random_flip_left_right(img, seed=2222)\n",
        "    img = tf.image.random_flip_up_down(img, seed=3333)\n",
        "    return img, label\n",
        "\n",
        "# map the augmentations, creating a new Dataset\n",
        "augmented_train_ds = train_ds.map(rotate_augmentation, num_parallel_calls=AUTOTUNE)\n",
        "augmented_train_ds = augmented_train_ds.map(flip_augmentation, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "augmented_val_ds = val_ds.map(rotate_augmentation, num_parallel_calls=AUTOTUNE)\n",
        "augmented_val_ds = augmented_val_ds.map(flip_augmentation, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# concatenate the augmented and original datasets\n",
        "train_ds = train_ds.concatenate(augmented_train_ds)\n",
        "val_ds = val_ds.concatenate(augmented_val_ds)"
      ],
      "metadata": {
        "id": "2EjOkAzN3epJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# double the number of samples in the training and validation splits, due to our augmentation procedure\n",
        "n_train = len(train_labels)*2\n",
        "n_val = len(val_labels)*2\n",
        "n_test = len(test_labels)\n",
        "\n",
        "# shuffle over the entire dataset, seeding the shuffling for reproducible results\n",
        "train_ds = train_ds.shuffle(n_train, seed=208, reshuffle_each_iteration=True)\n",
        "val_ds = val_ds.shuffle(n_val, seed=208, reshuffle_each_iteration=True)\n",
        "test_ds = test_ds.shuffle(n_test, seed=208, reshuffle_each_iteration=True)"
      ],
      "metadata": {
        "id": "8f3_wbN13erf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_check = 0\n",
        "for element in train_ds:\n",
        "    n_train_check = n_train_check + 1\n",
        "print(n_train_check)"
      ],
      "metadata": {
        "id": "lZDA6G0w3etz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_val_check = 0\n",
        "for element in val_ds:\n",
        "    n_val_check = n_val_check + 1\n",
        "print(n_val_check)"
      ],
      "metadata": {
        "id": "0epKqtVW3ewb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_test_check = 0\n",
        "for element in test_ds:\n",
        "    n_test_check = n_test_check + 1\n",
        "print(n_test_check)"
      ],
      "metadata": {
        "id": "9ur03HK73ezj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check that the image was read in correctly\n",
        "for image, label in train_ds.take(1):\n",
        "    print(\"image shape : \", image.numpy().shape)\n",
        "    print(\"label       : \", label.numpy())"
      ],
      "metadata": {
        "id": "RXqLJ_Hp2q0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=4, ncols=10, sharex=True, sharey=True, figsize=(20,10))\n",
        "\n",
        "i = 0\n",
        "\n",
        "for image, label in train_ds.take(10):\n",
        "    ax[0,i].imshow(image[:,:,0])\n",
        "    ax[0,i].set_title('{} - {}'.format(label.numpy(), 'R'))\n",
        "    ax[1,i].imshow(image[:,:,1])\n",
        "    ax[1,i].set_title('{} - {}'.format(label.numpy(), 'G'))\n",
        "    ax[2,i].imshow(image[:,:,2])\n",
        "    ax[2,i].set_title('{} - {}'.format(label.numpy(), 'B'))\n",
        "    ax[3,i].imshow(image)\n",
        "    ax[3,i].set_title('{} - {}'.format(label.numpy(), 'RGB'))\n",
        "\n",
        "    i = i+1"
      ],
      "metadata": {
        "id": "rMW-V3S74F3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3, sharex=True, sharey=True, figsize=(20,15))\n",
        "\n",
        "ax[0,0].set_xlim(0,1)\n",
        "\n",
        "i = 0\n",
        "\n",
        "for image, label in train_ds.take(3):\n",
        "    ax[i,0].hist(image[:,:,0].numpy().flatten())\n",
        "    ax[i,0].set_title('{} - {}'.format(label.numpy(), 'R'))\n",
        "    ax[i,1].hist(image[:,:,1].numpy().flatten())\n",
        "    ax[i,1].set_title('{} - {}'.format(label.numpy(), 'G'))\n",
        "    ax[i,2].hist(image[:,:,2].numpy().flatten())\n",
        "    ax[i,2].set_title('{} - {}'.format(label.numpy(), 'B'))\n",
        "\n",
        "    i = i+1"
      ],
      "metadata": {
        "id": "3ZZv3hce4F6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_batches_ds = train_ds.batch(BATCH_SIZE)\n",
        "val_batches_ds = val_ds.batch(BATCH_SIZE)\n",
        "test_batches_ds = test_ds.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "-vaG_RAJ4F9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, label_batch in train_batches_ds.take(1):\n",
        "    print(image_batch.shape)\n",
        "    print(label_batch.numpy())"
      ],
      "metadata": {
        "id": "4In_Hhms4F_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (128, 128, 3)\n",
        "\n",
        "# create the base model from the pre-trained model VGG16\n",
        "# note that, if using a Kaggle server, internet has to be turned on\n",
        "pretrained_model = tf.keras.applications.vgg16.VGG16(input_shape=IMG_SHAPE,\n",
        "                                                     include_top=False,\n",
        "                                                     weights='imagenet')\n",
        "\n",
        "# freeze the convolutional base\n",
        "pretrained_model.trainable = False"
      ],
      "metadata": {
        "id": "tH660T8E4GFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_batch = pretrained_model(image_batch)\n",
        "print(feature_batch.shape)"
      ],
      "metadata": {
        "id": "tFrZY5zG4GIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model.summary()"
      ],
      "metadata": {
        "id": "ts22P4fZ4GLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "metadata": {
        "id": "JmUBOQ__4GNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the initializers with a seed for reproducible behaviour\n",
        "prediction_layer = tf.keras.layers.Dense(1,\n",
        "                                         kernel_initializer=tf.keras.initializers.GlorotUniform(seed=1992),\n",
        "                                         bias_initializer=tf.keras.initializers.GlorotUniform(seed=1992))\n",
        "\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "metadata": {
        "id": "Hv8BMKOK4GQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([pretrained_model,\n",
        "                             global_average_layer,\n",
        "                             prediction_layer])"
      ],
      "metadata": {
        "id": "vosq-9Kx2q3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lrz1aZGx4cbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "vOwwO_uz4ceO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_epochs = 15\n",
        "steps_per_epoch = n_train//BATCH_SIZE\n",
        "validation_steps = 20\n",
        "\n",
        "loss0, accuracy0 = model.evaluate(val_batches_ds, steps=validation_steps)"
      ],
      "metadata": {
        "id": "uw7-cvJl4cg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_batches_ds,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=val_batches_ds,\n",
        "                    validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "-mqCIFw24cjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10,8), sharex=True)\n",
        "\n",
        "x_plot = np.arange(1, initial_epochs+1)\n",
        "\n",
        "ax[0].plot(x_plot, acc, '+-', label='training')\n",
        "ax[0].plot(x_plot, val_acc, '+-', label='validation')\n",
        "ax[0].legend()\n",
        "ax[0].set_ylabel('accuracy')\n",
        "ax[0].set_ylim(0.5, 1)\n",
        "ax[0].grid(ls='--', c='C7')\n",
        "ax[0].set_title('accuracy')\n",
        "\n",
        "ax[1].plot(x_plot, loss, '+-', label='training')\n",
        "ax[1].plot(x_plot, val_loss, '+-', label='validation')\n",
        "ax[1].legend()\n",
        "ax[1].set_ylabel('cross entropy')\n",
        "ax[1].set_ylim(0, 1)\n",
        "ax[1].grid(ls='--', c='C7')\n",
        "ax[1].set_title('loss')\n",
        "ax[1].set_xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W750c4UO4clg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze the layers\n",
        "pretrained_model.trainable = True\n",
        "\n",
        "# let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the pre-trained model: \", len(pretrained_model.layers))"
      ],
      "metadata": {
        "id": "cpAd8suI4cns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tune from this layer onwards\n",
        "fine_tune_at = 15\n",
        "\n",
        "# freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in pretrained_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "metadata": {
        "id": "hDnAwhwC4cqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate/75),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sA8qV22L2q6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.trainable_variables)"
      ],
      "metadata": {
        "id": "nMzFTEa62q9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_epochs = 50\n",
        "total_epochs =  initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_batches_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1]+1,\n",
        "                         validation_data=val_batches_ds,\n",
        "                         validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "CsL0rLrT2rAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc += history_fine.history['accuracy']\n",
        "val_acc += history_fine.history['val_accuracy']\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10,8), sharex=True)\n",
        "\n",
        "x_plot = np.arange(1, total_epochs+1)\n",
        "\n",
        "ax[0].plot(x_plot, acc, '+-', label='training')\n",
        "ax[0].plot(x_plot, val_acc, '+-', label='validation')\n",
        "ax[0].legend()\n",
        "ax[0].set_ylabel('accuracy')\n",
        "ax[0].set_ylim(0.5, 1)\n",
        "ax[0].grid(ls='--', c='C7')\n",
        "ax[0].set_title('accuracy')\n",
        "ax[0].axvline(initial_epochs, c='C7', ls='--')\n",
        "\n",
        "ax[1].plot(x_plot, loss, '+-', label='training')\n",
        "ax[1].plot(x_plot, val_loss, '+-', label='validation')\n",
        "ax[1].legend()\n",
        "ax[1].set_ylabel('cross entropy')\n",
        "ax[1].set_ylim(0, 1)\n",
        "ax[1].grid(ls='--', c='C7')\n",
        "ax[1].set_title('loss')\n",
        "ax[1].set_xlabel('epoch')\n",
        "ax[1].axvline(initial_epochs, c='C7', ls='--')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dWA0-Y0I4w0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(val_batches_ds)"
      ],
      "metadata": {
        "id": "ZK6eCgHW4w2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_batches_ds)"
      ],
      "metadata": {
        "id": "1MaIvgZM4w5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract images and labels from the batches, and store predictions\n",
        "eval_labels = np.array([])\n",
        "eval_predictions = np.array([])\n",
        "first = True\n",
        "for images, labels in test_batches_ds.take(-1): #take all the batches\n",
        "    if first:\n",
        "        eval_images = images.numpy()\n",
        "        first = False\n",
        "    else:\n",
        "        eval_images = np.concatenate((eval_images, images.numpy()), axis=0)\n",
        "    eval_labels = np.append(eval_labels, labels.numpy())\n",
        "    eval_predictions = np.append(eval_predictions, model.predict_on_batch(images).numpy())\n",
        "\n",
        "# convert predictions from logit to binary\n",
        "eval_predictions[eval_predictions>=0] = 1\n",
        "eval_predictions[eval_predictions<0] = 0\n",
        "\n",
        "# change dtype to int\n",
        "eval_predictions = eval_predictions.astype(int)\n",
        "eval_labels = eval_labels.astype(int)\n",
        "\n",
        "# check that we extracted the images and the labels correctly\n",
        "print(\"eval_images      : \", eval_images.shape)\n",
        "print(\"eval_labels      : \", eval_labels.shape)\n",
        "print(\"eval_predictions : \", eval_predictions.shape)"
      ],
      "metadata": {
        "id": "Pkz5eON84w7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_mtx = confusion_matrix(eval_labels, eval_predictions)\n",
        "confusion_mtx"
      ],
      "metadata": {
        "id": "Hra2Yvcz4w99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "TN = confusion_mtx[0,0]\n",
        "FN = confusion_mtx[1,0]\n",
        "TP = confusion_mtx[1,1]\n",
        "FP = confusion_mtx[0,1]\n",
        "F1 = f1_score(eval_labels, eval_predictions)\n",
        "\n",
        "print('accuracy = {:.4f}'.format((TP+TN)/np.sum(confusion_mtx)))\n",
        "print('positive recall = {:.4f}'.format(TP/(TP+FN)))\n",
        "print('negative recall = {:.4f}'.format(TN/(TN+FP)))\n",
        "print('positive precision = {:.4f}'.format(TP/(TP+FP)))\n",
        "print('negative precision = {:.4f}'.format(TN/(TN+FN)))"
      ],
      "metadata": {
        "id": "GSD3jMG6489N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_TP = TP/8\n",
        "b_FN = FN/8\n",
        "\n",
        "print('accuracy = {:.4f}'.format((b_TP+TN)/np.sum(2000)))\n",
        "print('positive recall = {:.4f}'.format(b_TP/(b_TP+b_FN)))\n",
        "print('negative recall = {:.4f}'.format(TN/(TN+FP)))\n",
        "print('positive precision = {:.4f}'.format(b_TP/(b_TP+FP)))\n",
        "print('negative precision = {:.4f}'.format(TN/(TN+b_FN)))"
      ],
      "metadata": {
        "id": "ZWZYfw6U49AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FP_eval_images = eval_images[(eval_labels==0)&(eval_predictions==1)]\n",
        "FN_eval_images = eval_images[(eval_labels==1)&(eval_predictions==0)]\n",
        "\n",
        "selected_FP = np.arange(10, dtype=int)*2\n",
        "selected_FN = np.arange(10, dtype=int)*2\n",
        "\n",
        "fig, ax = plt.subplots(nrows=4, ncols=5, sharex=True, sharey=True, figsize=(20,16))\n",
        "\n",
        "ax = ax.flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    ax[i].imshow(FP_eval_images[selected_FP[i]])\n",
        "\n",
        "for i in range(10):\n",
        "    ax[i+10].imshow(FN_eval_images[selected_FN[i]])\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HoAb7dxF49DO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}